NoOp {
name AnimateAxisCalculate_PM
tile_color 0xffff00ff
selected true
xpos 4233
ypos 220
hide_input true
addUserKnob {20 User l AnimateAxisCalculate}
addUserKnob {1 cam l "Camera Name"}
cam Camera5
addUserKnob {1 trk l "Tracker Name"}
trk Tracker1
addUserKnob {3 REF_FRAME l "Ref Frame"}
REF_FRAME 16
addUserKnob {7 REF_DEPTH l "Ref Depth(m)" t "Ref Depth in m at Ref Frame"}
REF_DEPTH 2
addUserKnob {26 ""}
addUserKnob {3 BAKE_FIRST l "First Frame"}
BAKE_FIRST 1
addUserKnob {3 BAKE_LAST l "Last Frame" -STARTLINE}
BAKE_LAST 32
addUserKnob {26 ""}
addUserKnob {22 calculate l "CALCULATE 3D Axis" T "\"\"\"\ntracker_to_3d_axis.py  —  Centroid translation + Procrustes rotation\n=====================================================================\nSolves animated translate + rotate on a 3D Axis from Tracker + Camera.\n\nTRANSLATION:  Centroid of 2D tracks → back-project at estimated depth.\nROTATION:     Kabsch rigid alignment between reference and per-frame 3D points.\n\"\"\"\n\nimport nuke\nimport numpy as np\nimport math\n\n\n# ---------------------------------------------------------------------------\n# Rotation helpers\n# ---------------------------------------------------------------------------\n\ndef _rx(a):\n    c, s = math.cos(a), math.sin(a)\n    return np.array(\[\[1,0,0],\[0,c,-s],\[0,s,c]], dtype=np.float64)\n\ndef _ry(a):\n    c, s = math.cos(a), math.sin(a)\n    return np.array(\[\[c,0,s],\[0,1,0],\[-s,0,c]], dtype=np.float64)\n\ndef _rz(a):\n    c, s = math.cos(a), math.sin(a)\n    return np.array(\[\[c,-s,0],\[s,c,0],\[0,0,1]], dtype=np.float64)\n\n\ndef rotation_matrix(rx_deg, ry_deg, rz_deg, order=0):\n    rx = math.radians(rx_deg)\n    ry = math.radians(ry_deg)\n    rz = math.radians(rz_deg)\n    Rx, Ry, Rz = _rx(rx), _ry(ry), _rz(rz)\n    if   order == 0: return Rz @ Ry @ Rx\n    elif order == 1: return Ry @ Rz @ Rx\n    elif order == 2: return Rz @ Rx @ Ry\n    elif order == 3: return Rx @ Rz @ Ry\n    elif order == 4: return Ry @ Rx @ Rz\n    elif order == 5: return Rx @ Ry @ Rz\n    else:            return Rz @ Ry @ Rx\n\n\ndef rot_to_euler_xyz(R):\n    sy = math.sqrt(R\[0,0]**2 + R\[1,0]**2)\n    if sy > 1e-6:\n        rx = math.atan2( R\[2,1], R\[2,2])\n        ry = math.atan2(-R\[2,0], sy)\n        rz = math.atan2( R\[1,0], R\[0,0])\n    else:\n        rx = math.atan2(-R\[1,2], R\[1,1])\n        ry = math.atan2(-R\[2,0], sy)\n        rz = 0.0\n    return math.degrees(rx), math.degrees(ry), math.degrees(rz)\n\n\n# ---------------------------------------------------------------------------\n# Camera\n# ---------------------------------------------------------------------------\n\ndef _get_node_matrix(node, frame):\n    tx = node\['translate'].getValueAt(frame, 0)\n    ty = node\['translate'].getValueAt(frame, 1)\n    tz = node\['translate'].getValueAt(frame, 2)\n    rx = node\['rotate'].getValueAt(frame, 0)\n    ry = node\['rotate'].getValueAt(frame, 1)\n    rz = node\['rotate'].getValueAt(frame, 2)\n    rot_order = int(node\['rot_order'].getValue())\n    R = rotation_matrix(rx, ry, rz, rot_order)\n    M = np.eye(4, dtype=np.float64)\n    M\[:3, :3] = R\n    M\[:3,  3] = \[tx, ty, tz]\n    parent = node.input(0)\n    if parent and parent.Class() in ('Axis2', 'Axis', 'TransformGeo'):\n        M = _get_node_matrix(parent, frame) @ M\n    return M\n\n\ndef get_cam(cam, frame):\n    fmt = nuke.root().format()\n    W, H = float(fmt.width()), float(fmt.height())\n    focal  = cam\['focal'].getValueAt(frame)\n    hapert = cam\['haperture'].getValueAt(frame)\n    vapert = cam\['vaperture'].getValueAt(frame)\n    K = np.array(\[\[focal/hapert*W, 0, W*0.5],\n                  \[0, focal/vapert*H, H*0.5],\n                  \[0, 0, 1]], dtype=np.float64)\n    M_c2w = _get_node_matrix(cam, frame)\n    M_w2c = np.linalg.inv(M_c2w)\n    return K, M_c2w, M_w2c\n\n\ndef unproject_pixel(px, py, depth, K, M_c2w):\n    x_cam = (px - K\[0,2]) / K\[0,0] * depth\n    y_cam = (py - K\[1,2]) / K\[1,1] * depth\n    z_cam = -depth\n    return (M_c2w @ np.array(\[x_cam, y_cam, z_cam, 1.0]))\[:3]\n\n\ndef world_to_cam_depth(p_world, M_w2c):\n    p_cam = M_w2c @ np.array(\[p_world\[0], p_world\[1], p_world\[2], 1.0])\n    return -p_cam\[2]\n\n\n# ---------------------------------------------------------------------------\n# Tracker\n# ---------------------------------------------------------------------------\n\ndef _parse_tracker_layout(tracker_node):\n    tk     = tracker_node\['tracks']\n    script = tk.toScript()\n    lines  = script.strip().split('\\n')\n    header = lines\[0].strip().strip('\{\}').split()\n    num_cols   = int(header\[1])\n    num_tracks = int(header\[2])\n    x_col, y_col = 2, 3\n    col_idx = 0\n    for line in lines\[1:]:\n        line = line.strip()\n        if not line.startswith('\{'):\n            continue\n        parts = line.strip('\{\}').split()\n        if len(parts) >= 4:\n            if parts\[3] == 'track_x': x_col = col_idx\n            elif parts\[3] == 'track_y': y_col = col_idx\n        col_idx += 1\n        if col_idx >= num_cols:\n            break\n    return num_cols, num_tracks, x_col, y_col\n\n\ndef get_tracker_2d(tracker_node, frame, layout):\n    num_cols, num_tracks, x_col, y_col = layout\n    tk  = tracker_node\['tracks']\n    pts, ids = \[], \[]\n    for t in range(num_tracks):\n        base = t * num_cols\n        if tk.getValueAt(frame, base):\n            pts.append(\[tk.getValueAt(frame, base + x_col),\n                        tk.getValueAt(frame, base + y_col)])\n            ids.append(t)\n    if not pts:\n        return np.zeros((0, 2), dtype=np.float64), ids\n    return np.array(pts, dtype=np.float64), ids\n\n\n# ---------------------------------------------------------------------------\n# Kabsch — rotation only\n# ---------------------------------------------------------------------------\n\ndef kabsch_rotation(P, Q):\n    \"\"\"\n    Find R such that Q_centered ≈ R @ P_centered  (least-squares rotation).\n    P: Nx3 source,  Q: Nx3 target.\n    Returns proper rotation R (det=+1).\n    \"\"\"\n    Pc = P - P.mean(axis=0)\n    Qc = Q - Q.mean(axis=0)\n    H = Pc.T @ Qc\n    U, S, Vt = np.linalg.svd(H)\n    d = np.linalg.det(Vt.T @ U.T)\n    D = np.diag(\[1.0, 1.0, d])\n    return Vt.T @ D @ U.T\n\n\n# ---------------------------------------------------------------------------\n# Main solver\n# ---------------------------------------------------------------------------\n\ndef solve(tracker_node, cam_node, ref_depth, ref_frame, first, last):\n\n    layout = _parse_tracker_layout(tracker_node)\n\n    # ---- Bootstrap 3D reference points ----\n    K_ref, M_c2w_ref, M_w2c_ref = get_cam(cam_node, ref_frame)\n    pts2d_ref, track_ids = get_tracker_2d(tracker_node, ref_frame, layout)\n\n    if len(pts2d_ref) < 3:\n        nuke.message(\"Only %d tracks on ref frame. Need >=3.\" % len(pts2d_ref))\n        return None\n\n    pts3d_ref = np.array(\[\n        unproject_pixel(p\[0], p\[1], ref_depth, K_ref, M_c2w_ref)\n        for p in pts2d_ref\n    ])\n\n    # Compute reference 2D centroid and its 3D position (for consistent translation)\n    centroid_2d_ref = pts2d_ref.mean(axis=0)\n    centroid_3d_ref = unproject_pixel(\n        centroid_2d_ref\[0], centroid_2d_ref\[1], ref_depth, K_ref, M_c2w_ref)\n\n    # ---- Create Axis ----\n    axis = nuke.createNode('Axis2', inpanel=False)\n    axis.setName('PnP_Solve_Axis')\n    axis\['rot_order'].setValue('XYZ')\n    axis\['translate'].setAnimated()\n    axis\['rotate'].setAnimated()\n\n    nuke.Undo.begin('Centroid+Procrustes 3D Axis solve')\n\n    errors, skipped = \[], \[]\n\n    for frame in range(first, last + 1):\n        try:\n            pts2d_f, ids_f = get_tracker_2d(tracker_node, frame, layout)\n            ref_map = \{tid: idx for idx, tid in enumerate(track_ids)\}\n            m3d, m2d = \[], \[]\n            for j, tid in enumerate(ids_f):\n                if tid in ref_map:\n                    m3d.append(pts3d_ref\[ref_map\[tid]])\n                    m2d.append(pts2d_f\[j])\n\n            if len(m3d) < 3:\n                skipped.append(frame)\n                continue\n\n            K_f, M_c2w_f, M_w2c_f = get_cam(cam_node, frame)\n\n            # --- Translation: centroid back-projection ---\n            depths = \[world_to_cam_depth(p, M_w2c_f) for p in m3d]\n            avg_depth = np.mean(depths)\n            if avg_depth <= 0.01:\n                skipped.append(frame)\n                continue\n            c2d = np.array(m2d).mean(axis=0)\n            t_world = unproject_pixel(c2d\[0], c2d\[1], avg_depth, K_f, M_c2w_f)\n\n            # --- Rotation: Kabsch ---\n            m3d_arr = np.array(m3d)\n            pts3d_frame = np.array(\[\n                unproject_pixel(m2d\[i]\[0], m2d\[i]\[1],\n                                max(0.01, world_to_cam_depth(m3d\[i], M_w2c_f)),\n                                K_f, M_c2w_f)\n                for i in range(len(m3d))\n            ])\n            R_f = kabsch_rotation(m3d_arr, pts3d_frame)\n            erx, ery, erz = rot_to_euler_xyz(R_f)\n\n            axis\['translate'].setValueAt(float(t_world\[0]), frame, 0)\n            axis\['translate'].setValueAt(float(t_world\[1]), frame, 1)\n            axis\['translate'].setValueAt(float(t_world\[2]), frame, 2)\n            axis\['rotate'].setValueAt(erx, frame, 0)\n            axis\['rotate'].setValueAt(ery, frame, 1)\n            axis\['rotate'].setValueAt(erz, frame, 2)\n\n        except Exception as e:\n            errors.append('Frame %d: %s' % (frame, str(e)))\n\n    nuke.Undo.end()\n    return axis\n\n\n# ---------------------------------------------------------------------------\n# Configuration\n# ---------------------------------------------------------------------------\n\n# Get the current Nuke node\nref_node = nuke.thisNode()\n\ncamF = ref_node\['cam'].getValue()\ntrkF = ref_node\['trk'].getValue()\nREF_FRAMEF = int(ref_node\['REF_FRAME'].getValue())\nBAKE_FIRSTF = int(ref_node\['BAKE_FIRST'].getValue())\nBAKE_LASTF = int(ref_node\['BAKE_LAST'].getValue())\nREF_DEPTHF = ref_node\['REF_DEPTH'].getValue()\n\nTRACKER_NODE = trkF\nCAMERA_NODE  = camF\nREF_FRAME    = REF_FRAMEF\nREF_DEPTH    = REF_DEPTHF\nBAKE_FIRST   = BAKE_FIRSTF\nBAKE_LAST    = BAKE_LASTF\n\n# ---------------------------------------------------------------------------\n# Run\n# ---------------------------------------------------------------------------\n\ntracker_node = nuke.toNode(TRACKER_NODE)\ncamera_node  = nuke.toNode(CAMERA_NODE)\n\nif tracker_node is None:\n    nuke.message(\"Cannot find Tracker node: \" + TRACKER_NODE)\nelif camera_node is None:\n    nuke.message(\"Cannot find Camera node: \" + CAMERA_NODE)\nelse:\n    solve(tracker_node, camera_node, REF_DEPTH, REF_FRAME, BAKE_FIRST, BAKE_LAST)" +STARTLINE}
addUserKnob {22 calculate_only l "CALCULATE 3D Axis Translation Only" -STARTLINE T "\"\"\"\ntracker_to_3d_axis.py  —  Centroid translation only\n=====================================================================\nSolves animated translate on a 3D Axis from Tracker + Camera.\n\nTRANSLATION:  Centroid of 2D tracks → back-project at estimated depth.\n\"\"\"\n\nimport nuke\nimport numpy as np\nimport math\n\n\n# ---------------------------------------------------------------------------\n# Rotation helpers (for camera matrix reconstruction)\n# ---------------------------------------------------------------------------\n\ndef _rx(a):\n    c, s = math.cos(a), math.sin(a)\n    return np.array(\[\[1,0,0],\[0,c,-s],\[0,s,c]], dtype=np.float64)\n\ndef _ry(a):\n    c, s = math.cos(a), math.sin(a)\n    return np.array(\[\[c,0,s],\[0,1,0],\[-s,0,c]], dtype=np.float64)\n\ndef _rz(a):\n    c, s = math.cos(a), math.sin(a)\n    return np.array(\[\[c,-s,0],\[s,c,0],\[0,0,1]], dtype=np.float64)\n\n\ndef rotation_matrix(rx_deg, ry_deg, rz_deg, order=0):\n    rx = math.radians(rx_deg)\n    ry = math.radians(ry_deg)\n    rz = math.radians(rz_deg)\n    Rx, Ry, Rz = _rx(rx), _ry(ry), _rz(rz)\n    if   order == 0: return Rz @ Ry @ Rx\n    elif order == 1: return Ry @ Rz @ Rx\n    elif order == 2: return Rz @ Rx @ Ry\n    elif order == 3: return Rx @ Rz @ Ry\n    elif order == 4: return Ry @ Rx @ Rz\n    elif order == 5: return Rx @ Ry @ Rz\n    else:            return Rz @ Ry @ Rx\n\n\n# ---------------------------------------------------------------------------\n# Camera\n# ---------------------------------------------------------------------------\n\ndef _get_node_matrix(node, frame):\n    tx = node\['translate'].getValueAt(frame, 0)\n    ty = node\['translate'].getValueAt(frame, 1)\n    tz = node\['translate'].getValueAt(frame, 2)\n    rx = node\['rotate'].getValueAt(frame, 0)\n    ry = node\['rotate'].getValueAt(frame, 1)\n    rz = node\['rotate'].getValueAt(frame, 2)\n    rot_order = int(node\['rot_order'].getValue())\n    R = rotation_matrix(rx, ry, rz, rot_order)\n    M = np.eye(4, dtype=np.float64)\n    M\[:3, :3] = R\n    M\[:3,  3] = \[tx, ty, tz]\n    parent = node.input(0)\n    if parent and parent.Class() in ('Axis2', 'Axis', 'TransformGeo'):\n        M = _get_node_matrix(parent, frame) @ M\n    return M\n\n\ndef get_cam(cam, frame):\n    fmt = nuke.root().format()\n    W, H = float(fmt.width()), float(fmt.height())\n    focal  = cam\['focal'].getValueAt(frame)\n    hapert = cam\['haperture'].getValueAt(frame)\n    vapert = cam\['vaperture'].getValueAt(frame)\n    K = np.array(\[\[focal/hapert*W, 0, W*0.5],\n                  \[0, focal/vapert*H, H*0.5],\n                  \[0, 0, 1]], dtype=np.float64)\n    M_c2w = _get_node_matrix(cam, frame)\n    M_w2c = np.linalg.inv(M_c2w)\n    return K, M_c2w, M_w2c\n\n\ndef unproject_pixel(px, py, depth, K, M_c2w):\n    x_cam = (px - K\[0,2]) / K\[0,0] * depth\n    y_cam = (py - K\[1,2]) / K\[1,1] * depth\n    z_cam = -depth\n    return (M_c2w @ np.array(\[x_cam, y_cam, z_cam, 1.0]))\[:3]\n\n\ndef world_to_cam_depth(p_world, M_w2c):\n    p_cam = M_w2c @ np.array(\[p_world\[0], p_world\[1], p_world\[2], 1.0])\n    return -p_cam\[2]\n\n\n# ---------------------------------------------------------------------------\n# Tracker\n# ---------------------------------------------------------------------------\n\ndef _parse_tracker_layout(tracker_node):\n    tk     = tracker_node\['tracks']\n    script = tk.toScript()\n    lines  = script.strip().split('\\n')\n    header = lines\[0].strip().strip('\{\}').split()\n    num_cols   = int(header\[1])\n    num_tracks = int(header\[2])\n    x_col, y_col = 2, 3\n    col_idx = 0\n    for line in lines\[1:]:\n        line = line.strip()\n        if not line.startswith('\{'):\n            continue\n        parts = line.strip('\{\}').split()\n        if len(parts) >= 4:\n            if parts\[3] == 'track_x': x_col = col_idx\n            elif parts\[3] == 'track_y': y_col = col_idx\n        col_idx += 1\n        if col_idx >= num_cols:\n            break\n    return num_cols, num_tracks, x_col, y_col\n\n\ndef get_tracker_2d(tracker_node, frame, layout):\n    num_cols, num_tracks, x_col, y_col = layout\n    tk  = tracker_node\['tracks']\n    pts, ids = \[], \[]\n    for t in range(num_tracks):\n        base = t * num_cols\n        if tk.getValueAt(frame, base):\n            pts.append(\[tk.getValueAt(frame, base + x_col),\n                        tk.getValueAt(frame, base + y_col)])\n            ids.append(t)\n    if not pts:\n        return np.zeros((0, 2), dtype=np.float64), ids\n    return np.array(pts, dtype=np.float64), ids\n\n\n# ---------------------------------------------------------------------------\n# Main solver  (translate only)\n# ---------------------------------------------------------------------------\n\ndef solve(tracker_node, cam_node, ref_depth, ref_frame, first, last):\n\n    layout = _parse_tracker_layout(tracker_node)\n\n    # ---- Bootstrap 3D reference points ----\n    K_ref, M_c2w_ref, M_w2c_ref = get_cam(cam_node, ref_frame)\n    pts2d_ref, track_ids = get_tracker_2d(tracker_node, ref_frame, layout)\n\n    if len(pts2d_ref) < 1:\n        nuke.message(\"No tracks on ref frame %d.\" % ref_frame)\n        return None\n\n    pts3d_ref = np.array(\[\n        unproject_pixel(p\[0], p\[1], ref_depth, K_ref, M_c2w_ref)\n        for p in pts2d_ref\n    ])\n\n    # ---- Create Axis ----\n    axis = nuke.createNode('Axis2', inpanel=False)\n    axis.setName('PnP_Solve_Axis')\n    axis\['translate'].setAnimated()\n\n    nuke.Undo.begin('Centroid 3D Axis solve')\n\n    skipped = \[]\n\n    for frame in range(first, last + 1):\n        try:\n            pts2d_f, ids_f = get_tracker_2d(tracker_node, frame, layout)\n            ref_map = \{tid: idx for idx, tid in enumerate(track_ids)\}\n            m3d, m2d = \[], \[]\n            for j, tid in enumerate(ids_f):\n                if tid in ref_map:\n                    m3d.append(pts3d_ref\[ref_map\[tid]])\n                    m2d.append(pts2d_f\[j])\n\n            if len(m3d) < 1:\n                skipped.append(frame)\n                continue\n\n            K_f, M_c2w_f, M_w2c_f = get_cam(cam_node, frame)\n\n            # --- Translation: centroid back-projection ---\n            depths = \[world_to_cam_depth(p, M_w2c_f) for p in m3d]\n            avg_depth = np.mean(depths)\n            if avg_depth <= 0.01:\n                skipped.append(frame)\n                continue\n            c2d = np.array(m2d).mean(axis=0)\n            t_world = unproject_pixel(c2d\[0], c2d\[1], avg_depth, K_f, M_c2w_f)\n\n            axis\['translate'].setValueAt(float(t_world\[0]), frame, 0)\n            axis\['translate'].setValueAt(float(t_world\[1]), frame, 1)\n            axis\['translate'].setValueAt(float(t_world\[2]), frame, 2)\n\n        except Exception:\n            skipped.append(frame)\n\n    nuke.Undo.end()\n    return axis\n\n\n# ---------------------------------------------------------------------------\n# Configuration\n# ---------------------------------------------------------------------------\n\nref_node = nuke.thisNode()\n\nTRACKER_NODE = ref_node\['trk'].getValue()\nCAMERA_NODE  = ref_node\['cam'].getValue()\nREF_FRAME    = int(ref_node\['REF_FRAME'].getValue())\nREF_DEPTH    = ref_node\['REF_DEPTH'].getValue()\nBAKE_FIRST   = int(ref_node\['BAKE_FIRST'].getValue())\nBAKE_LAST    = int(ref_node\['BAKE_LAST'].getValue())\n\n# ---------------------------------------------------------------------------\n# Run\n# ---------------------------------------------------------------------------\n\ntracker_node = nuke.toNode(TRACKER_NODE)\ncamera_node  = nuke.toNode(CAMERA_NODE)\n\nif tracker_node is None:\n    nuke.message(\"Cannot find Tracker node: \" + TRACKER_NODE)\nelif camera_node is None:\n    nuke.message(\"Cannot find Camera node: \" + CAMERA_NODE)\nelse:\n    solve(tracker_node, camera_node, REF_DEPTH, REF_FRAME, BAKE_FIRST, BAKE_LAST)"}
addUserKnob {26 ""}
addUserKnob {26 _3 l "" +STARTLINE T "AnimateAxisCalculate_PM v1.00 by Peter Mercell / 2026 / Experimental node"}
addUserKnob {26 _2 l "" +STARTLINE T "<a style=\"color: #999999;\"><a style=\"color: #999999;\" href=\"http://www.petermercell.com\" target=\"_blank\" rel=\"noopener\">www.petermercell.com</a>"}
}
